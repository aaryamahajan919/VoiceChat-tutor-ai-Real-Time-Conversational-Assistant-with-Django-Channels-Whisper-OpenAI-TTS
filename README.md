# ğŸ™ï¸ VoiceChat Tutor â€“ Real-Time AI Speaking Assistant

> A real-time voice assistant web app that listens to your speech, understands it using GPT, and responds back with a natural voice â€” powered by Django Channels, Whisper, OpenAI, and ElevenLabs.

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Django](https://img.shields.io/badge/Django-REST%20API-green?logo=django)
![WebSockets](https://img.shields.io/badge/WebSockets-Realtime-orange?logo=websocket)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT3.5/4-black?logo=openai)
![TTS](https://img.shields.io/badge/Text--to--Speech-ElevenLabs-purple)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

---

## ğŸš€ Demo

```
#demo-link yet to build 
```
ğŸ”Š Talk into your mic â†’ ğŸ§ Hear AI speak back in real-time!

---

## ğŸ§  What It Does

- ğŸ¤ Takes live voice input via browser microphone
- ğŸ§¾ Transcribes audio using [OpenAI Whisper](https://github.com/openai/whisper)
- ğŸ’¬ Sends transcribed text to [OpenAI GPT-3.5/4](https://platform.openai.com/)
- ğŸ—£ï¸ Converts GPT response into audio using [ElevenLabs TTS](https://www.elevenlabs.io/)
- ğŸ”„ Returns audio over WebSocket in real time

---

## ğŸ“¦ Tech Stack

| Component | Technology |
|----------|-------------|
| Backend  | Django, Django Channels, Django REST Framework |
| Realtime | WebSockets, Redis |
| STT      | OpenAI Whisper (or local `whisper` model) |
| NLP      | OpenAI GPT-3.5/4 |
| TTS      | ElevenLabs API (or pyttsx3 for offline fallback) |
| Infra    | Redis, Render / AWS EC2 / ngrok (for testing) |

---

## ğŸ—‚ï¸ Project Structure

```
voicechat_tutor/
â”œâ”€â”€ backend/                 # Django backend with WebSocket consumers
â”‚   â”œâ”€â”€ voicechat/           # STT, LLM, TTS processing logic
â”‚   â”œâ”€â”€ backend/             # Django settings and routing
â”œâ”€â”€ frontend/                # HTML/JS frontend to record voice and play reply
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/voicechat-tutor.git
cd voicechat-tutor
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Install Redis
- On Ubuntu: `sudo apt install redis`
- On Mac: `brew install redis`

### 4. Start Redis
```bash
redis-server
```

### 5. Run Django Dev Server
```bash
python manage.py runserver
```

### 6. Open Frontend
Open `frontend/index.html` in a browser (use Live Server in VS Code or deploy to Netlify).

---

## ğŸ“¡ WebSocket Flow

```plaintext
Browser Mic ğŸ™ï¸
     â†“ (binary)
 Django Channels (WebSocket)
     â†“
  Whisper STT
     â†“
OpenAI GPT-3.5
     â†“
ElevenLabs TTS
     â†“
Back to Browser ğŸ” (base64 audio)
```

---

## âš™ï¸ Environment Variables

Create a `.env` file or use system env vars:
```
OPENAI_API_KEY=your_openai_key
ELEVENLABS_API_KEY=your_elevenlabs_key
VOICE_ID=your_elevenlabs_voice_id
```

---

## âœ… Features

- â±ï¸ Real-time STT and TTS
- ğŸ§  GPT-4 conversation logic
- ğŸŒ WebSocket bidirectional flow
- ğŸ³ Optional Docker deployment
- ğŸ“¤ Deployable on Render, EC2, or localhost

---

## ğŸ§ª Future Ideas

- Multi-language support
- Emotion-aware voice tone
- Voice-based interview simulator
- Save chat history to S3

---

## ğŸ“„ License

MIT License. Feel free to fork and remix.

---

## ğŸ™‹â€â™‚ï¸ About Me

Built with â¤ï¸ by [Aarya Mahajan]
ğŸ“« Connect on [LinkedIn](https://www.linkedin.com/in/aarya-mahajan-034191231/)

---

## â­ï¸ Support the Project

If you find this helpful, give a â­ on GitHub and share it!
